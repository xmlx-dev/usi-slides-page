<!DOCTYPE html>
<html lang="en"><head>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-html/tabby.min.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-html.min.css" rel="stylesheet" data-mode="light">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.2.313">

  <meta name="author" content="Kacper Sokol">
  <title>Machine Learning Explainability: Exploring Automated Decision-Making Through Transparent Modelling and Peeking Inside Black Boxes - Defining Explainability</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
    }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/theme/quarto.css" id="theme">
  <link href="../../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">

  .callout {
    margin-top: 1em;
    margin-bottom: 1em;  
    border-radius: .25rem;
  }

  .callout.callout-style-simple { 
    padding: 0em 0.5em;
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
    display: flex;
  }

  .callout.callout-style-default {
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
  }

  .callout .callout-body-container {
    flex-grow: 1;
  }

  .callout.callout-style-simple .callout-body {
    font-size: 1rem;
    font-weight: 400;
  }

  .callout.callout-style-default .callout-body {
    font-size: 0.9rem;
    font-weight: 400;
  }

  .callout.callout-captioned.callout-style-simple .callout-body {
    margin-top: 0.2em;
  }

  .callout:not(.callout-captioned) .callout-body {
      display: flex;
  }

  .callout:not(.no-icon).callout-captioned.callout-style-simple .callout-content {
    padding-left: 1.6em;
  }

  .callout.callout-captioned .callout-header {
    padding-top: 0.2em;
    margin-bottom: -0.2em;
  }

  .callout.callout-captioned .callout-caption  p {
    margin-top: 0.5em;
    margin-bottom: 0.5em;
  }
    
  .callout.callout-captioned.callout-style-simple .callout-content  p {
    margin-top: 0;
  }

  .callout.callout-captioned.callout-style-default .callout-content  p {
    margin-top: 0.7em;
  }

  .callout.callout-style-simple div.callout-caption {
    border-bottom: none;
    font-size: .9rem;
    font-weight: 600;
    opacity: 75%;
  }

  .callout.callout-style-default  div.callout-caption {
    border-bottom: none;
    font-weight: 600;
    opacity: 85%;
    font-size: 0.9rem;
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-default div.callout-content {
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-simple .callout-icon::before {
    height: 1rem;
    width: 1rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 1rem 1rem;
  }

  .callout.callout-style-default .callout-icon::before {
    height: 0.9rem;
    width: 0.9rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 0.9rem 0.9rem;
  }

  .callout-caption {
    display: flex
  }
    
  .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  .callout.no-icon::before {
    display: none !important;
  }

  .callout.callout-captioned .callout-body > .callout-content > :last-child {
    margin-bottom: 0.5rem;
  }

  .callout.callout-captioned .callout-icon::before {
    margin-top: .5rem;
    padding-right: .5rem;
  }

  .callout:not(.callout-captioned) .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  /* Callout Types */

  div.callout-note {
    border-left-color: #4582ec !important;
  }

  div.callout-note .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEU0lEQVRYCcVXTWhcVRQ+586kSUMMxkyaElstCto2SIhitS5Ek8xUKV2poatCcVHtUlFQk8mbaaziwpWgglJwVaquitBOfhQXFlqlzSJpFSpIYyXNjBNiTCck7x2/8/LeNDOZxDuEkgOXe++553zfefee+/OYLOXFk3+1LLrRdiO81yNqZ6K9cG0P3MeFaMIQjXssE8Z1JzLO9ls20MBZX7oG8w9GxB0goaPrW5aNMp1yOZIa7Wv6o2ykpLtmAPs/vrG14Z+6d4jpbSKuhdcSyq9wGMPXjonwmESXrriLzFGOdDBLB8Y6MNYBu0dRokSygMA/mrun8MGFN3behm6VVAwg4WR3i6FvYK1T7MHo9BK7ydH+1uurECoouk5MPRyVSBrBHMYwVobG2aOXM07sWrn5qgB60rc6mcwIDJtQrnrEr44kmy+UO9r0u9O5/YbkS9juQckLed3DyW2XV/qWBBB3ptvI8EUY3I9p/67OW+g967TNr3Sotn3IuVlfMLVnsBwH4fsnebJvyGm5GeIUA3jljERmrv49SizPYuq+z7c2H/jlGC+Ghhupn/hcapqmcudB9jwJ/3jvnvu6vu5lVzF1fXyZuZZ7U8nRmVzytvT+H3kilYvH09mLWrQdwFSsFEsxFVs5fK7A0g8gMZjbif4ACpKbjv7gNGaD8bUrlk8x+KRflttr22JEMRUbTUwwDQScyzPgedQHZT0xnx7ujw2jfVfExwYHwOsDTjLdJ2ebmeQIlJ7neo41s/DrsL3kl+W2lWvAga0tR3zueGr6GL78M3ifH0rGXrBC2aAR8uYcIA5gwV8zIE8onoh8u0Fca/ciF7j1uOzEnqcIm59sEXoGc0+z6+H45V1CvAvHcD7THztu669cnp+L0okAeIc6zjbM/24LgGM1gZk7jnRu1aQWoU9sfUOuhrmtaPIO3YY1KLLWZaEO5TKUbMY5zx8W9UJ6elpLwKXbsaZ4EFl7B4bMtDv0iRipKoDQT2sNQI9b1utXFdYisi+wzZ/ri/1m7QfDgEuvgUUEIJPq3DhX/5DWNqIXDOweC2wvIR90Oq3lDpdMIgD2r0dXvGdsEW5H6x6HLRJYU7C69VefO1x8Gde1ZFSJLfWS1jbCnhtOPxmpfv2LXOA2Xk2tvnwKKPFuZ/oRmwBwqRQDcKNeVQkYcOjtWVBuM/JuYw5b6isojIkYxyYAFn5K7ZBF10fea52y8QltAg6jnMqNHFBmGkQ1j+U43HMi2xMar1Nv0zGsf1s8nUsmUtPOOrbFIR8bHFDMB5zL13Gmr/kGlCkUzedTzzmzsaJXhYawnA3UmARpiYj5ooJZiUoxFRtK3X6pgNPv+IZVPcnwbOl6f+aBaO1CNvPW9n9LmCp01nuSaTRF2YxHqZ8DYQT6WsXT+RD6eUztwYLZ8rM+rcPxamv1VQzFUkzFXvkiVrySGQgJNvXHJAxiU3/NwiC03rSf05VBaPtu/Z7/B8Yn/w7eguloAAAAAElFTkSuQmCC');
  }

  div.callout-note.callout-style-default .callout-caption {
    background-color: #dae6fb
  }

  div.callout-important {
    border-left-color: #d9534f !important;
  }

  div.callout-important .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEKklEQVRYCcVXTWhcVRS+575MJym48A+hSRFr00ySRQhURRfd2HYjk2SSTokuBCkU2o0LoSKKraKIBTcuFCoidGFD08nkBzdREbpQ1EDNIv8qSGMFUboImMSZd4/f9zJv8ibJMC8xJQfO3HPPPef7zrvvvnvviIkpC9nsw0UttFunbUhpFzFtarSd6WJkStVMw5xyVqYTvkwfzuf/5FgtkVoB0729j1rjXwThS7Vio+Mo6DNnvLfahoZ+i/o32lULuJ3NNiz7q6+pyAUkJaFF6JwaM2lUJlV0MlnQn5aTRbEu0SEqHUa0A4AdiGuB1kFXRfVyg5d87+Dg4DL6m2TLAub60ilj7A1Ec4odSAc8X95sHh7+ZRPCFo6Fnp7HfU/fBng/hi10CjCnWnJjsxvDNxWw0NfV6Rv5GgP3I3jGWXumdTD/3cbEOP2ZbOZp69yniG3FQ9z1jD7bnBu9Fc2tKGC2q+uAJOQHBDRiZX1x36o7fWBs7J9ownbtO+n0/qWkvW7UPIfc37WgT6ZGR++EOJyeQDSb9UB+DZ1G6DdLDzyS+b/kBCYGsYgJbSQHuThGKRcw5xdeQf8YdNHsc6ePXrlSYMBuSIAFTGAtQo+VuALo4BX83N190NWZWbynBjhOHsmNfFWLeL6v+ynsA58zDvvAC8j5PkbOcXCMg2PZFk3q8MjI7WAG/Dp9AwP7jdGBOOQkAvlFUB+irtm16I1Zw9YBcpGTGXYmk3kQIC/Cds55l+iMI3jqhjAuaoe+am2Jw5GT3Nbz3CkE12NavmzN5+erJW7046n/CH1RO/RVa8lBLozXk9uqykkGAyRXLWlLv5jyp4RFsG5vGVzpDLnIjTWgnRy2Rr+tDKvRc7Y8AyZq10jj8DqXdnIRNtFZb+t/ZRtXcDiVnzpqx8mPcDWxgARUqx0W1QB9MeUZiNrV4qP+Ehc+BpNgATsTX8ozYKL2NtFYAHc84fG7ndxUPr+AR/iQSns7uSUufAymwDOb2+NjK27lEFocm/EE2WpyIy/Hi66MWuMKJn8RvxIcj87IM5Vh9663ziW36kR0HNenXuxmfaD8JC7tfKbrhFr7LiZCrMjrzTeGx+PmkosrkNzW94ObzwocJ7A1HokLolY+AvkTiD/q1H0cN48c5EL8Crkttsa/AXQVDmutfyku0E7jShx49XqV3MFK8IryDhYVbj7Sj2P2eBxwcXoe8T8idsKKPRcnZw1b+slFTubwUwhktrfnAt7J++jwQtLZcm3sr9LQrjRzz6cfMv9aLvgmnAGvpoaGLxM4mAEaLV7iAzQ3oU0IvD5x9ix3yF2RAAuYAOO2f7PEFWCXZ4C9Pb2UsgDeVnFSpbFK7/IWu7TPTvBqzbGdCHOJQSxiEjt6IyZmxQyEJHv6xyQsYk//moVFsN2zP6fRImjfq7/n/wFDguUQFNEwugAAAABJRU5ErkJggg==');
  }

  div.callout-important.callout-style-default .callout-caption {
    background-color: #f7dddc
  }

  div.callout-warning {
    border-left-color: #f0ad4e !important;
  }

  div.callout-warning .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAETklEQVRYCeVWW2gcVRg+58yaTUnizqbipZeX4uWhBEniBaoUX1Ioze52t7sRq6APio9V9MEaoWlVsFasRq0gltaAPuxms8lu0gcviE/FFOstVbSIxgcv6SU7EZqmdc7v9+9mJtNks51NTUH84ed889/PP+cmxP+d5FIbMJmNbpREu4WUkiTtCicKny0l1pIKmBzovF2S+hIJHX8iEu3hZJ5lNZGqyRrGSIQpq15AzF28jgpeY6yk6GVdrfFqdrD6Iw+QlB8g0YS2g7dyQmXM/IDhBhT0UCiRf59lfqmmDvzRt6kByV/m4JjtzuaujMUM2c5Z2d6JdKrRb3K2q6mA+oYVz8JnDdKPmmNthzkAk/lN63sYPgevrguc72aZX/L9C6x09GYyxBgCX4NlvyGUHOKELlm5rXeR1kchuChJt4SSwyddZRXgvwMGvYo4QSlk3/zkHD8UHxwVJA6zjZZqP8v8kK8OWLnIZtLyCAJagYC4rTGW/9Pqj92N/c+LUaAj27movwbi19tk/whRCIE7Q9vyI6yvRpftAKVTdUjOW40X3h5OXsKCdmFcx0xlLJoSuQngnrJe7Kcjm4OMq9FlC7CMmScQANuNvjfP3PjGXDBaUQmbp296S5L4DrpbrHN1T87ZVEZVCzg1FF0Ft+dKrlLukI+/c9ENo+TvlTDbYFvuKPtQ9+l052rXrgKoWkDAFnvh0wTOmYn8R5f4k/jN/fZiCM1tQx9jQQ4ANhqG4hiL0qIFTGViG9DKB7GYzgubnpofgYRwO+DFjh0Zin2m4b/97EDkXkc+f6xYAPX0KK2I/7fUQuwzuwo/L3AkcjugPNixC8cHf0FyPjWlItmLxWw4Ou9YsQCr5fijMGoD/zpdRy95HRysyXA74MWOnscpO4j2y3HAVisw85hX5+AFBRSHt4ShfLFkIMXTqyKFc46xdzQM6XbAi702a7sy04J0+feReMFKp5q9esYLCqAZYw/k14E/xcLLsFElaornTuJB0svMuJINy8xkIYuL+xPAlWRceH6+HX7THJ0djLUom46zREu7tTkxwmf/FdOZ/sh6Q8qvEAiHpm4PJ4a/doJe0gH1t+aHRgCzOvBvJedEK5OFE5jpm4AGP2a8Dxe3gGJ/pAutug9Gp6he92CsSsWBaEcxGx0FHytmIpuqGkOpldqNYQK8cSoXvd+xLxXADw0kf6UkJNFtdo5MOgaLjiQOQHcn+A6h5NuL2s0qsC2LOM75PcF3yr5STuBSAcGG+meA14K/CI21HcS4LBT6tv0QAh8Dr5l93AhZzG5ZJ4VxAqdZUEl9z7WJ4aN+svMvwHHL21UKTd1mqvChH7/Za5xzXBBKrUcB0TQ+Ulgkfbi/H/YT5EptrGzsEK7tR1B7ln9BBwckYfMiuSqklSznIuoIIOM42MQO+QnduCoFCI0bpkzjCjddHPN/F+2Yu+sd9bKNpVwHhbS3LluK/0zgfwD0xYI5dXuzlQAAAABJRU5ErkJggg==');
  }

  div.callout-warning.callout-style-default .callout-caption {
    background-color: #fcefdc
  }

  div.callout-tip {
    border-left-color: #02b875 !important;
  }

  div.callout-tip .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAADr0lEQVRYCe1XTWgTQRj9ZjZV8a9SPIkKgj8I1bMHsUWrqYLVg4Ue6v9BwZOxSYsIerFao7UiUryIqJcqgtpimhbBXoSCVxUFe9CTiogUrUp2Pt+3aUI2u5vdNh4dmMzOzHvvezuz8xNFM0mjnbXaNu1MvFWRXkXEyE6aYOYJpdW4IXuA4r0fo8qqSMDBU0v1HJUgVieAXxzCsdE/YJTdFcVIZQNMyhruOMJKXYFoLfIfIvVIMWdsrd+Rpd86ZmyzzjJmLStqRn0v8lzkb4rVIXvnpScOJuAn2ACC65FkPzEdEy4TPWRLJ2h7z4cArXzzaOdKlbOvKKX25Wl00jSnrwVxAg3o4dRxhO13RBSdNvH0xSARv3adTXbBdTf64IWO2vH0LT+cv4GR1DJt+DUItaQogeBX/chhbTBxEiZ6gftlDNXTrvT7co4ub5A6gp9HIcHvzTa46OS5fBeP87Qm0fQkr4FsYgVQ7Qg+ZayaDg9jhg1GkWj8RG6lkeSacrrHgDaxdoBiZPg+NXV/KifMuB6//JmYH4CntVEHy/keA6x4h4CU5oFy8GzrBS18cLJMXcljAKB6INjWsRcuZBWVaS3GDrqB7rdapVIeA+isQ57Eev9eCqzqOa81CY05VLd6SamW2wA2H3SiTbnbSxmzfp7WtKZkqy4mdyAlGx7ennghYf8voqp9cLSgKdqNfa6RdRsAAkPwRuJZNbpByn+RrJi1RXTwdi8RQF6ymDwGMAtZ6TVE+4uoKh+MYkcLsT0Hk8eAienbiGdjJHZTpmNjlbFJNKDVAp2fJlYju6IreQxQ08UJDNYdoLSl6AadO+fFuCQqVMB1NJwPm69T04Wv5WhfcWyfXQB+wXRs1pt+nCknRa0LVzSA/2B+a9+zQJadb7IyyV24YAxKp2Jqs3emZTuNnKxsah+uabKbMk7CbTgJx/zIgQYErIeTKRQ9yD9wxVof5YolPHqaWo7TD6tJlh7jQnK5z2n3+fGdggIOx2kaa2YI9QWarc5Ce1ipNWMKeSG4DysFF52KBmTNMmn5HqCFkwy34rDg05gDwgH3bBi+sgFhN/e8QvRn8kbamCOhgrZ9GJhFDgfcMHzFb6BAtjKpFhzTjwv1KCVuxHvCbsSiEz4CANnj84cwHdFXAbAOJ4LTSAawGWFn5tDhLMYz6nWeU2wJfIhmIJBefcd/A5FWQWGgrWzyORZ3Q6HuV+Jf0Bj+BTX69fm1zWgK7By1YTXchFDORywnfQ7GpzOo6S+qECrsx2ifVQAAAABJRU5ErkJggg==');
  }

  div.callout-tip.callout-style-default .callout-caption {
    background-color: #ccf1e3
  }

  div.callout-caution {
    border-left-color: #fd7e14 !important;
  }

  div.callout-caution .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAACV0lEQVRYCdVWzWoUQRCuqp2ICBLJXgITZL1EfQDBW/bkzUMUD7klD+ATSHBEfAIfQO+iXsWDxJsHL96EHAwhgzlkg8nBg25XWb0zIb0zs9muYYWkoKeru+vn664fBqElyZNuyh167NXJ8Ut8McjbmEraKHkd7uAnAFku+VWdb3reSmRV8PKSLfZ0Gjn3a6Xlcq9YGb6tADjn+lUfTXtVmaZ1KwBIvFI11rRXlWlatwIAAv2asaa9mlB9wwygiDX26qaw1yYPzFXg2N1GgG0FMF8Oj+VIx7E/03lHx8UhvYyNZLN7BwSPgekXXLribw7w5/c8EF+DBK5idvDVYtEEwMeYefjjLAdEyQ3M9nfOkgnPTEkYU+sxMq0BxNR6jExrAI31H1rzvLEfRIdgcv1XEdj6QTQAS2wtstEALLG1yEZ3QhH6oDX7ExBSFEkFINXH98NTrme5IOaaA7kIfiu2L8A3qhH9zRbukdCqdsA98TdElyeMe5BI8Rs2xHRIsoTSSVFfCFCWGPn9XHb4cdobRIWABNf0add9jakDjQJpJ1bTXOJXnnRXHRf+dNL1ZV1MBRCXhMbaHqGI1JkKIL7+i8uffuP6wVQAzO7+qVEbF6NbS0LJureYcWXUUhH66nLR5rYmva+2tjRFtojkM2aD76HEGAD3tPtKM309FJg5j/K682ywcWJ3PASCcycH/22u+Bh7Aa0ehM2Fu4z0SAE81HF9RkB21c5bEn4Dzw+/qNOyXr3DCTQDMBOdhi4nAgiFDGCinIa2owCEChUwD8qzd03PG+qdW/4fDzjUMcE1ZpIAAAAASUVORK5CYII=');
  }

  div.callout-caution.callout-style-default .callout-caption {
    background-color: #ffe5d0
  }

  </style>
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
  <script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>
</head>
<body class="quarto-dark">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title">Defining Explainability</h1>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Kacper Sokol 
</div>
</div>
</div>

</section><section id="TOC">
<nav role="doc-toc"> 
<h2 id="toc-title">Topics</h2>
<ul>
<li><a href="#/nomenclature" id="/toc-nomenclature">Nomenclature</a></li>
<li><a href="#/what-is-explainability" id="/toc-what-is-explainability">What Is Explainability?</a></li>
<li><a href="#/defining-explainability" id="/toc-defining-explainability">Defining Explainability</a></li>
<li><a href="#/examples" id="/toc-examples">Examples</a></li>
<li><a href="#/wrap-up" id="/toc-wrap-up">Wrap Up</a></li>
</ul>
</nav>
</section>
<section>
<section id="nomenclature" class="title-slide slide level1 center">
<h1>Nomenclature</h1>

</section>
<section id="black-box" class="slide level2">
<h2>Black Box</h2>
<blockquote>
<p>A system or automated process whose <strong>internal workings are opaque</strong> to the observer – its operation may only be traced by analysing its behaviour through its inputs and outputs</p>
</blockquote>
</section>
<section id="black-box-meta-subs.ctd" class="slide level2">
<h2>Black Box &nbsp;&nbsp;&nbsp;</h2>
<p>Sources of opaqueness:</p>
<ol type="1">
<li>a proprietary system, which may be <strong>transparent to its creators</strong>, but operates as a black box</li>
<li>a system that is <strong>too complex</strong> to be comprehend by <strong>any human</strong></li>
</ol>

<aside><div>
<p><span class="citation" data-cites="rudin2019stop">(<a href="#/bibliography" role="doc-biblioref" onclick="">Rudin 2019</a>)</span></p>
</div></aside></section>
<section id="black-box-meta-subs.ctd-1" class="slide level2">
<h2>Black Box &nbsp;&nbsp;&nbsp;</h2>
<blockquote>
<p>Spectrum of opaqueness determined by the context (audience, purpose, etc.)</p>
</blockquote>
<p><img data-src="../../assets/figures/blackboxiness.svg" style="width:75.0%" alt="Shades of black-boxiness"></p>

<aside class="notes">
<ul>
<li>Instead of binary yes/no opaque, it seems more appropriate to have a continuous scale</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><div>
<p><span class="citation" data-cites="sokol2021explainability">(<a href="#/bibliography" role="doc-biblioref" onclick="">Sokol and Flach 2021</a>)</span></p>
</div></aside></section>
<section id="transparency-interpretability-explainability" class="slide level2">
<h2>Transparency, Interpretability, Explainability, …</h2>
<div class="cell" data-fig-width="55%" data-execution_count="2">
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="definitions_files/figure-revealjs/cell-3-output-1.png" alt="ML explainability terms" width="614" height="317"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="transparency-interpretability-explainability-meta-subs.ctd" class="slide level2">
<h2>Transparency, Interpretability, Explainability, … &nbsp;&nbsp;&nbsp;</h2>
<div class="columns">
<div class="column" style="width:25%;">
<ul>
<li>explainability</li>
<li>intelligibility</li>
<li>simulatability</li>
<li>sensemaking</li>
<li>cause</li>
</ul>
</div><div class="column" style="width:25%;">
<ul>
<li>observability</li>
<li>comprehensibility</li>
<li>explicitness</li>
<li>insight</li>
</ul>
</div><div class="column" style="width:25%;">
<ul>
<li>transparency</li>
<li>understandability</li>
<li>justification</li>
<li>evidence</li>
</ul>
</div><div class="column" style="width:25%;">
<ul>
<li>explicability</li>
<li>interpretability</li>
<li>rationalisation</li>
<li>reason</li>
</ul>
</div>
</div>
<aside class="notes">
<ul>
<li><p>A lot of different terms are used interchangeably</p></li>
<li><p>They are (re)defined in a large number of papers</p></li>
<li><p>We will try to organise this catalogue of words</p></li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<!-- #%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#% --->
</section></section>
<section>
<section id="what-is-explainability" class="title-slide slide level1 center">
<h1>What Is Explainability?</h1>

</section>
<section id="lack-of-a-universally-accepted-definition" class="slide level2">
<h2>Lack of a universally accepted definition</h2>
<blockquote>
<p>Interpretability is the degree to which a human can understand the cause of a decision</p>
</blockquote>
<blockquote>
<p>Explanation is an answer to a “Why?” question</p>
</blockquote>

<aside><div>
<p><span class="citation" data-cites="miller2019explanation biran2017explanation">(<a href="#/bibliography" role="doc-biblioref" onclick="">Miller 2019</a>; <a href="#/bibliography" role="doc-biblioref" onclick="">Biran and Cotton 2017</a>)</span></p>
</div></aside></section>
<section id="lack-of-a-universally-accepted-definition-meta-subs.ctd" class="slide level2">
<h2>Lack of a universally accepted definition &nbsp;&nbsp;&nbsp;</h2>
<blockquote>
<p>Explanations should answer “Why?” and “Why-should?” questions until such questions can no longer be asked</p>
</blockquote>

<aside><div>
<p><span class="citation" data-cites="gilpin2018explaining">(<a href="#/bibliography" role="doc-biblioref" onclick="">Gilpin et al. 2018</a>)</span></p>
</div></aside></section>
<section id="lack-of-a-universally-accepted-definition-meta-subs.ctd-1" class="slide level2">
<h2>Lack of a universally accepted definition &nbsp;&nbsp;&nbsp;</h2>
<blockquote>
<p>Explanations “giv[e] a reason for a prediction” and answer “how a system arrives at its prediction”</p>
</blockquote>
<blockquote>
<p>Justifications “put an explanation in a context” and convey “why we should believe that the prediction is correct”</p>
</blockquote>

<aside class="notes">
<ul>
<li>justifications do not necessarily communicate how the system truly works</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><div>
<p><span class="citation" data-cites="biran2014justification">(<a href="#/bibliography" role="doc-biblioref" onclick="">Biran and McKeown 2014</a>)</span></p>
</div></aside></section>
<section id="lack-of-a-universally-accepted-definition-meta-subs.ctd-2" class="slide level2">
<h2>Lack of a universally accepted definition &nbsp;&nbsp;&nbsp;</h2>
<blockquote>
<p>Transparency is a <em>passive</em> characteristic of a model that allows humans to make sense of it on different levels</p>
</blockquote>
<blockquote>
<p>Explainability is an <em>active</em> characteristic of a model that is achieved through actions and procedures employed (by the model) to clarify its functioning for a certain audience</p>
</blockquote>

<aside><div>
<p><span class="citation" data-cites="arrieta2020explainable">(<a href="#/bibliography" role="doc-biblioref" onclick="">Arrieta et al. 2020</a>)</span></p>
</div></aside></section>
<section id="lack-of-a-universally-accepted-definition-meta-subs.ctd-3" class="slide level2">
<h2>Lack of a universally accepted definition &nbsp;&nbsp;&nbsp;</h2>
<blockquote>
<p>Interpretability is the degree to which a human can consistently predict the model’s result</p>
</blockquote>

<aside><div>
<p><span class="citation" data-cites="kim2016examples">(<a href="#/bibliography" role="doc-biblioref" onclick="">Kim, Khanna, and Koyejo 2016</a>)</span></p>
</div></aside></section>
<section id="lack-of-a-universally-accepted-definition-meta-subs.ctd-4" class="slide level2">
<h2>Lack of a universally accepted definition &nbsp;&nbsp;&nbsp;</h2>
<blockquote>
<p>Transparency is the ability of a human to comprehend the (ante-hoc) mechanism employed by a predictive model on three levels</p>
</blockquote>

<div class="fragment">
<ul>
<li class="fragment"><strong>decomposability</strong> – appreciation of individual components (input, parameterisation and computation) that constitute a predictive system</li>
<li class="fragment"><strong>algorithmic transparency</strong> – understanding the modelling process embodied by a predictive algorithm</li>
<li class="fragment"><strong>simulatability</strong> enables humans to simulate a decisive process in vivo at the level of the entire model</li>
</ul>
</div>
<aside><div>
<p><span class="citation" data-cites="lipton2018mythos">(<a href="#/bibliography" role="doc-biblioref" onclick="">Lipton 2018</a>)</span></p>
</div></aside></section>
<section id="lack-of-a-universally-accepted-definition-meta-subs.ctd-5" class="slide level2">
<h2>Lack of a universally accepted definition &nbsp;&nbsp;&nbsp;</h2>
<p>Marr’s three-level hierarchy of understanding information processing devices</p>
<ol type="1">
<li><strong>computational theory</strong> – abstract specification of the problem at hand and the overall goal.</li>
<li><strong>representation and algorithm</strong> – implementation details and selection of an appropriate representation</li>
<li><strong>hardware implementation</strong> – physical realisation of the explained problem</li>
</ol>

<aside class="notes">
<ul>
<li>These three tiers are only loosely related</li>
<li>Some phenomena may be explained at only one or two of them</li>
<li>Identify which of these levels need to be covered in each individual case to arrive at understanding</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><div>
<p><span class="citation" data-cites="marr1982vision">(<a href="#/bibliography" role="doc-biblioref" onclick="">Marr 1982</a>)</span></p>
</div></aside></section>
<section id="lack-of-a-universally-accepted-definition-meta-subs.ctd-6" class="slide level2">
<h2>Lack of a universally accepted definition &nbsp;&nbsp;&nbsp;</h2>
<p>Understanding why birds fly cannot be achieved by only studying their feathers:</p>
<blockquote>
<p>In order to understand bird flight, we have to understand aerodynamics; only then do the structure of feathers and the different shapes of birds’ wings make sense.</p>
</blockquote>
</section>
<section id="lack-of-a-universally-accepted-definition-meta-subs.ctd-7" class="slide level2">
<h2>Lack of a universally accepted definition &nbsp;&nbsp;&nbsp;</h2>
<p>Fidelity-based understanding</p>
<ul>
<li><strong>completeness</strong> – how truthful the understanding is overall (<em>generality</em>)</li>
<li><strong>soundness</strong> – how accurate the understanding is for a particular phenomenon (<em>specificity</em>)</li>
</ul>

<aside class="notes">
<ul>
<li><p>Complete understanding can be applied to other domains</p></li>
<li><p>The depth of understanding, i.e., the level of (over)simplification</p></li>
<li><p>completeness without soundness is likely to be too broad, hence uninformative</p></li>
<li><p>the opposite can be too specific to the same effect</p></li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><div>
<p><span class="citation" data-cites="kulesza2013too">(<a href="#/bibliography" role="doc-biblioref" onclick="">Kulesza et al. 2013</a>)</span></p>
</div></aside></section>
<section id="lack-of-a-universally-accepted-definition-meta-subs.ctd-8" class="slide level2">
<h2>Lack of a universally accepted definition &nbsp;&nbsp;&nbsp;</h2>
<p>Mental models withing the completeness–soundness landscape</p>
<ul>
<li><strong>functional</strong> – operationalisation without understanding</li>
<li><strong>structural</strong> – appreciation of the underlying mechanism</li>
</ul>

<aside class="notes">
<ul>
<li>Electricity and light bulb scenario</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><div>
<p><span class="citation" data-cites="kulesza2013too">(<a href="#/bibliography" role="doc-biblioref" onclick="">Kulesza et al. 2013</a>)</span></p>
</div></aside></section>
<section id="approaches-to-defining-xml-concepts" class="slide level2">
<h2>Approaches to defining XML concepts</h2>
<ul>
<li>no definition</li>
<li>inherently intuitive – <em>You know it when you see it!</em></li>
<li>assuming terms are synonymous</li>
</ul>
</section>
<section id="approaches-to-defining-xml-concepts-meta-subs.ctd" class="slide level2">
<h2>Approaches to defining XML concepts &nbsp;&nbsp;&nbsp;</h2>
<ul>
<li><p>circular or tautological definitions</p>
<ul>
<li>“something is explainable when we can interpret it”</li>
<li>“interpretability is making sense of ML models”</li>
<li>“interpretable systems are explainable if their operations can be understood by humans”</li>
<li>“intelligibility is the possibility to comprehended something”</li>
</ul></li>
<li><p>dictionary definitions</p>
<ul>
<li>to interpret is “to explain […] the meaning of”</li>
<li>to explain is to “present in understandable terms”</li>
</ul></li>
</ul>
</section>
<section id="approaches-to-defining-xml-concepts-meta-subs.ctd-1" class="slide level2">
<h2>Approaches to defining XML concepts &nbsp;&nbsp;&nbsp;</h2>
<ul>
<li><p>hierarchical and ontological definitions</p>
<ul>
<li>creating a web of connections</li>
</ul></li>
<li><p>component-based – pairings between keywords and technical component or properties</p>
<ul>
<li>data are understandable; models are transparent; predictions are explainable</li>
<li>interpretability is determined by fidelity, brevity and relevance of the insights</li>
</ul></li>
</ul>
<aside class="notes">
<ul>
<li>hierarchies and ontologies are difficult to parse, follow and apply</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section></section>
<section>
<section id="defining-explainability" class="title-slide slide level1 center">
<h1>Defining Explainability</h1>

</section>
<section id="human-agnostic-definitions" class="slide level2">
<h2>Human-agnostic definitions</h2>
<ul>
<li>(technical) desiderata of explainers</li>
<li>(abstract) properties of explanations</li>
</ul>
</section>
<section id="human-centred-definitions" class="slide level2">
<h2>Human-centred definitions</h2>
<ul>
<li>the role and needs of (human) explainees</li>
<li>the goal of explanations (with respect to explainees)</li>
</ul>
<div class="fragment">
<br>
<hr>
<p><br></p>
<ul>
<li>The Chinese Room Theorem <span class="citation" data-cites="searle1980minds">(<a href="#/bibliography" role="doc-biblioref" onclick="">Searle 1980</a>)</span></li>
</ul>
<aside class="notes">
<ul>
<li>problem with simulatability</li>
<li>replication-based definitions, more broadly</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</div>
</section>
<section id="terminology-key-concepts" class="slide level2">
<h2>Terminology &amp; Key Concepts</h2>
<ul>
<li><strong>Transparency</strong> – <em>insight</em> (of arbitrary complexity) into operation of a system</li>
<li><strong>Background Knowledge</strong> – implicit or explicit <em>exogenous information</em> encompassing (operational) <em>context</em> such as application area, stakeholder and audience (domain expertise)</li>
<li><strong>Reasoning</strong> – <em>algorithmic</em> or <em>mental processing</em> of information</li>
</ul>
</section>
<section id="definition" class="slide level2">
<h2>Definition</h2>
<p><span class="math display">\[
\texttt{Explainability} \; =
\]</span> <span class="math display">\[
\underbrace{ \texttt{Reasoning} \left( \texttt{Transparency} \; | \; \texttt{Background Knowledge} \right)}_{\textit{understanding}}
\]</span></p>

<aside class="notes">
<ul>
<li>Explainability is a socially-grounded technology</li>
<li>It provides insights that lead to understanding</li>
<li>Understanding largely depends upon the explanation recipients, who come with a diverse range of background knowledge, experience, mental models and expectations (context)</li>
<li>It is a process – a loop</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><div>
<p><span class="citation" data-cites="sokol2021explainability">(<a href="#/bibliography" role="doc-biblioref" onclick="">Sokol and Flach 2021</a>)</span></p>
</div></aside></section>
<section id="goal" class="slide level2">
<h2>Goal</h2>
<p><br></p>
<blockquote>
<p>Explainability → <strong>explainee</strong> walking away with <strong>understanding</strong></p>
</blockquote>
<aside class="notes">
<ul>
<li>This notion both conceptualises explainability and fixes its evaluation criterion (as we will see in the next module)</li>
<li>Note that it is not about <strong>task completion</strong> but <strong>understanding</strong></li>
<li>Recall The Chinese Room Argument</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="understanding-explainability-transparency" class="slide level2">
<h2>Understanding, explainability &amp; transparency</h2>
<p><br></p>
<blockquote>
<p>A <strong>continuous spectrum</strong> rather than a binary property</p>
</blockquote>
<p><br></p>

<img data-src="../../assets/figures/blackboxiness.svg" style="width:75.0%" alt="Shades of black-boxiness" class="r-stretch"><aside class="notes">
<ul>
<li><strong>Explainability is not a binary property; it is a continuous spectrum</strong></li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<!-- #%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#% --->
</section></section>
<section>
<section id="examples" class="title-slide slide level1 center">
<h1>Examples</h1>
<aside class="notes">
<ul>
<li>transparency is different from explainability – both overcome opaqueness, but only the latter leads to understanding</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="linear-models" class="slide level2">
<h2>Linear Models</h2>
<p><span class="math display">\[
f(\mathbf{x}) = 0.2 \;\; + \;\; 0.25 \times x_1 \;\; + \;\; 0.7 \times x_4 \;\; - \;\; 0.2 \times x_5 \;\; - \;\; 0.9 \times x_7
\]</span></p>
<p><br></p>
<p><span class="math display">\[
\mathbf{x} = (0.4, \ldots, 1, \frac{1}{2}, \ldots \frac{1}{3})
\]</span></p>
<div class="fragment">
<p><br></p>
<p><span class="math display">\[
f(\mathbf{x}) = 0.2 \;\; \underbrace{+0.1}_{x_1} \;\; \underbrace{+0.7}_{x_4} \;\; \underbrace{-0.1}_{x_5} \;\; \underbrace{-0.3}_{x_7} \;\; = \;\; 0.6
\]</span></p>
<aside class="notes">
<ul>
<li><p>linear models are transparent given a reasonable number of features</p></li>
<li><p>with the right ML and domain background knowledge they become explainable</p>
<ul>
<li>normalised features</li>
<li>effect of feature correlation</li>
<li>meaning of features and coefficients</li>
</ul></li>
</ul>
<p>– the explainee can reason about their properties, leading to an explanation based on understanding - visualisation can help – refer back to XXX</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</div>
</section>
<section id="linear-models-meta-subs.ctd" class="slide level2">
<h2>Linear Models &nbsp;&nbsp;&nbsp;</h2>

<img data-src="definitions_files/figure-revealjs/cell-4-output-1.png" class="r-stretch quarto-figure-center"></section>
<section id="linear-models-meta-subs.ctd-1" class="slide level2">
<h2>Linear Models &nbsp;&nbsp;&nbsp;</h2>

<img data-src="../../assets/figures/force-plot-x.svg" style="width:100.0%" alt="Force plot explanation" class="r-stretch quarto-figure-center"></section>
<section id="decision-trees" class="slide level2">
<h2>Decision Trees</h2>
<div class="cell" data-execution_count="5">
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="definitions_files/figure-revealjs/cell-6-output-1.png" width="614" height="426"></p>
</figure>
</div>
</div>
</div>
<aside class="notes">
<ul>
<li>visualisation of a shallow decision tree can be considered both transparent, and arguably explainable assuming that the explainee understands how to navigate its structure (ML background knowledge) and the features are meaningful (domain background knowledge);</li>
<li>people were shown to believe that the feature used by the root-node split is the most important attribute <span class="citation" data-cites="bell2022s">(<a href="#/bibliography" role="doc-biblioref" onclick="">Bell et al. 2022</a>)</span></li>
<li>it is up to the explainee to reason about these insights</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="decision-trees-meta-subs.ctd" class="slide level2">
<h2>Decision Trees &nbsp;&nbsp;&nbsp;</h2>
<div class="cell" data-execution_count="6">
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="definitions_files/figure-revealjs/cell-7-output-1.png" width="614" height="426"></p>
</figure>
</div>
</div>
</div>
<aside class="notes">
<ul>
<li><p>when the size of a tree increases, its visualisation loses the explanatory power because many explainees become unable to process and reason about its structure</p></li>
<li><p>restoring the explainability of a deep tree requires delegating the reasoning process to an algorithm that can digest its structure and output sought after insights in a concise representation</p></li>
<li><p>for explaining a prediction, the tree structure can be traversed to identify a similar instance with a different prediction, e.g., as encoded by two neighbouring leaves with a shared parent</p></li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<!-- #%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#% --->
</section></section>
<section>
<section id="wrap-up" class="title-slide slide level1 center">
<h1>Wrap Up</h1>

</section>
<section id="summary" class="slide level2">
<h2>Summary</h2>
<ul>
<li>Explainability is an elusive concept</li>
<li>Its definition relies on the broadly-understood context</li>
<li>It should be human-centred and goal-driven</li>
<li>It should lead to understanding</li>
</ul>
</section>
<section id="bibliography" class="slide level2 smaller scrollable">
<h2>Bibliography</h2>
<div id="refs" class="references csl-bib-body hanging-indent" role="doc-bibliography">
<div id="ref-arrieta2020explainable" class="csl-entry" role="doc-biblioentry">
Arrieta, Alejandro Barredo, Natalia Dı́az-Rodrı́guez, Javier Del Ser, Adrien Bennetot, Siham Tabik, Alberto Barbado, Salvador Garcı́a, et al. 2020. <span>“Explainable Artificial Intelligence (<span>XAI</span>): <span>Concepts</span>, Taxonomies, Opportunities and Challenges Toward Responsible <span>AI</span>.”</span> <em>Information Fusion</em> 58: 82–115.
</div>
<div id="ref-bell2022s" class="csl-entry" role="doc-biblioentry">
Bell, Andrew, Ian Solano-Kamaiko, Oded Nov, and Julia Stoyanovich. 2022. <span>“It’s Just Not That Simple: <span>An</span> Empirical Study of the Accuracy-Explainability Trade-Off in Machine Learning for Public Policy.”</span> In <em>2022 ACM Conference on Fairness, Accountability, and Transparency</em>, 248–66.
</div>
<div id="ref-biran2017explanation" class="csl-entry" role="doc-biblioentry">
Biran, Or, and Courtenay Cotton. 2017. <span>“Explanation and Justification in Machine Learning: <span>A</span> Survey.”</span> In <em>IJCAI-17 Workshop on Explainable AI (XAI)</em>, 8:8–13. 1.
</div>
<div id="ref-biran2014justification" class="csl-entry" role="doc-biblioentry">
Biran, Or, and Kathleen McKeown. 2014. <span>“Justification Narratives for Individual Classifications.”</span> In <em>Proceedings of the AutoML Workshop at ICML</em>, 2014:1–7.
</div>
<div id="ref-gilpin2018explaining" class="csl-entry" role="doc-biblioentry">
Gilpin, Leilani H, David Bau, Ben Z Yuan, Ayesha Bajwa, Michael Specter, and Lalana Kagal. 2018. <span>“Explaining Explanations: <span>An</span> Overview of Interpretability of Machine Learning.”</span> In <em>2018 IEEE 5<sup>th</sup> International Conference on Data Science and Advanced Analytics (DSAA)</em>, 80–89. IEEE.
</div>
<div id="ref-kim2016examples" class="csl-entry" role="doc-biblioentry">
Kim, Been, Rajiv Khanna, and Oluwasanmi O Koyejo. 2016. <span>“Examples Are Not Enough, Learn to Criticize! <span>Criticism</span> for Interpretability.”</span> In <em>Advances in Neural Information Processing Systems</em>, 2280–88.
</div>
<div id="ref-kulesza2013too" class="csl-entry" role="doc-biblioentry">
Kulesza, Todd, Simone Stumpf, Margaret Burnett, Sherry Yang, Irwin Kwan, and Weng-Keen Wong. 2013. <span>“Too Much, Too Little, or Just Right? <span>Ways</span> Explanations Impact End Users’ Mental Models.”</span> In <em>Visual Languages and Human-Centric Computing (VL/HCC), 2013 IEEE Symposium on</em>, 3–10. IEEE.
</div>
<div id="ref-lipton2018mythos" class="csl-entry" role="doc-biblioentry">
Lipton, Zachary C. 2018. <span>“The Mythos of Model Interpretability.”</span> <em>Communications of the ACM</em> 16 (3): 30:31–57. <a href="https://doi.org/10.1145/3236386.3241340">https://doi.org/10.1145/3236386.3241340</a>.
</div>
<div id="ref-marr1982vision" class="csl-entry" role="doc-biblioentry">
Marr, David. 1982. <em>Vision: <span>A</span> Computational Investigation into the Human Representation and Processing of Visual Information</em>. The MIT Press.
</div>
<div id="ref-miller2019explanation" class="csl-entry" role="doc-biblioentry">
Miller, Tim. 2019. <span>“Explanation in Artificial Intelligence: <span>Insights</span> from the Social Sciences.”</span> <em>Artificial Intelligence</em> 267: 1–38.
</div>
<div id="ref-rudin2019stop" class="csl-entry" role="doc-biblioentry">
Rudin, Cynthia. 2019. <span>“Stop Explaining Black Box Machine Learning Models for High Stakes Decisions and Use Interpretable Models Instead.”</span> <em>Nature Machine Intelligence</em> 1 (5): 206–15.
</div>
<div id="ref-searle1980minds" class="csl-entry" role="doc-biblioentry">
Searle, John R. 1980. <span>“Minds, Brains, and Programs.”</span> <em>Behavioral and Brain Sciences</em> 3 (3): 417–24.
</div>
<div id="ref-sokol2021explainability" class="csl-entry" role="doc-biblioentry">
Sokol, Kacper, and Peter Flach. 2021. <span>“Explainability Is in the Mind of the Beholder: <span>Establishing</span> the Foundations of Explainable Artificial Intelligence.”</span> <em>arXiv Preprint arXiv:2112.14466</em>.
</div>
</div>
</section>
<section id="questions" class="slide level2">
<h2>Questions</h2>
<center style="font-size: 750%;">
<p></p>
</center>

<aside><div>
<p><a href="mailto:kacper.sokol@rmit.edu.au">kacper.sokol@rmit.edu.au</a> <br> <a href="mailto:k.sokol@bristol.ac.uk">k.sokol@bristol.ac.uk</a></p>
</div></aside></section>
<section class="slide level2">

<p>&nbsp;</p>

<div class="footer footer-default">

</div>
</section></section>
    </div>
  </div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="../../site_libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="../../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="../../site_libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="../../site_libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="../../site_libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="../../site_libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="../../site_libs/revealjs/plugin/notes/notes.js"></script>
  <script src="../../site_libs/revealjs/plugin/search/search.js"></script>
  <script src="../../site_libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="../../site_libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'smaller': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: false,

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1680,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const clipboard = new window.ClipboardJS('.code-copy-button', {
        target: function(trigger) {
          return trigger.previousElementSibling;
        }
      });
      clipboard.on('success', function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        let tooltip;
        if (window.bootstrap) {
          button.setAttribute("data-bs-toggle", "tooltip");
          button.setAttribute("data-bs-placement", "left");
          button.setAttribute("data-bs-title", "Copied!");
          tooltip = new bootstrap.Tooltip(button, 
            { trigger: "manual", 
              customClass: "code-copy-button-tooltip",
              offset: [0, -8]});
          tooltip.show();    
        }
        setTimeout(function() {
          if (tooltip) {
            tooltip.hide();
            button.removeAttribute("data-bs-title");
            button.removeAttribute("data-bs-toggle");
            button.removeAttribute("data-bs-placement");
          }
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      });
      function tippyHover(el, contentFn) {
        const config = {
          allowHTML: true,
          content: contentFn,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'quarto-reveal',
          placement: 'bottom-start'
        };
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          return note.innerHTML;
        });
      }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>
    

</body></html>